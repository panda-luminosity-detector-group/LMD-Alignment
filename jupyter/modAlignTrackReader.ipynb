{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 320\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [9. 9.]\n",
      " [9. 9.]\n",
      " [9. 9.]\n",
      " [9. 9.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [9. 9.]\n",
      " [9. 9.]\n",
      " [9. 9.]\n",
      " [9. 9.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [9. 9.]\n",
      " [9. 9.]\n",
      " [9. 9.]\n",
      " [9. 9.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [5. 5.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [7. 7.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [8. 8.]\n",
      " [9. 9.]\n",
      " [9. 9.]\n",
      " [9. 9.]\n",
      " [9. 9.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import uproot, json\n",
    "\n",
    "# from util.matrix import loadMatrices, baseTransform\n",
    "\n",
    "np.set_printoptions(precision=6)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "def loadMatrices(filename):\n",
    "    with open(filename) as f:\n",
    "        result = json.load(f)\n",
    "    for key, value in result.items():\n",
    "        result[key] = np.array(value).reshape(4, 4)\n",
    "    return result\n",
    "\n",
    "def baseTransform(mat, matFromAtoB):\n",
    "    \"\"\"\n",
    "    Reminder: the way this works is that the matrix pointing from pnd to sen0 transforms a matrix IN sen0 back to Pnd\n",
    "    If you want to transform a matrix from Pnd to sen0, and you have the matrix to sen0, then you need to give\n",
    "    this function inv(matTo0). I know it's confusing, but that's the way this works.\n",
    "\n",
    "    Example: matrixInPanda = baseTransform(matrixInSensor, matrixPandaToSensor)\n",
    "    \"\"\"\n",
    "    return matFromAtoB @ mat @ np.linalg.inv(matFromAtoB)\n",
    "\n",
    "with open(\"../../input/sensorIDtoSectorID.json\", \"r\") as f:\n",
    "    sensorIDdict = json.load(f)\n",
    "    sectorIDlut = np.empty(len(sensorIDdict))\n",
    "\n",
    "    # create a look up table for fast sensorID -> sectorID translation\n",
    "    for key, value in sensorIDdict.items():\n",
    "        sectorIDlut[int(key)] = value\n",
    "\n",
    "print(f\"len: {len(sectorIDlut)}\")\n",
    "print(sectorIDlut.reshape((160, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len before mask: 100000\n",
      "len after mask: 99992\n",
      "hmmm...\n",
      "[array([ 38, 194,  22, 160,  31,  78, 234, 200,  71, 118, 274, 240, 314,\n",
      "        280], dtype=int32)\n",
      " array([  0, 169,   1,  28,  35,  40, 210,  40,  40, 236,  68,  41, 232,\n",
      "        236,  48, 233,  42,  49,  49,  49, 226, 209,  42,  47,  47,  43,\n",
      "         45,  80,  80,  80, 250, 272, 272, 272, 276, 276, 108,  85, 270,\n",
      "         88, 273,  91,  90, 248, 251,  82,  87, 120, 308, 308, 120, 290,\n",
      "        121, 312, 316, 148, 120, 121, 131, 126, 291, 294, 155, 158, 131,\n",
      "         73,  79, 243], dtype=int32)\n",
      " array([172,  37, 194, 199,  13, 161, 164, 160, 212, 224,  77, 224, 228,\n",
      "        234, 220,  53, 220, 201, 220, 221, 233,  47,  49, 218, 252, 117,\n",
      "        269, 252, 274, 260, 256,  93, 241, 267, 259, 259,  97, 292, 157,\n",
      "        309, 314, 300, 296, 133, 291, 294, 281, 302], dtype=int32)\n",
      " ...\n",
      " array([  2, 171,   9,  11, 176, 176,  24, 162, 198, 184,  30, 194, 193,\n",
      "        199,   4, 178, 178,  42, 211,  49,  51, 216, 216, 238,  64, 235,\n",
      "        202, 227,  70, 219, 221,  69,  82, 251,  89,  91, 275, 256, 256,\n",
      "        105, 242, 277, 110, 271, 259, 115, 118, 122, 291, 129, 131, 315,\n",
      "        296, 296, 145, 310, 282, 317], dtype=int32)\n",
      " array([ 15,  25,  28,  29,  55,  55,  65,  68,  69,  95, 105, 108, 109,\n",
      "        152, 135, 145, 148, 149, 159, 155], dtype=int32)\n",
      " array([  2,   8, 192, 160, 160,  42,  48, 232, 200, 200,  82,  88, 272,\n",
      "        240, 240, 122, 140, 128, 312, 280, 280, 126,  91], dtype=int32) ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m# path = \"/media/CacheDrive2TB/Arbeit/PandaRoot/macro/detectors/lmd/testFullChain/mom-1_5/\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m rootFileWildcard \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLumi_recoMerged_*.root:pndsim\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 80\u001b[0m resultArray \u001b[39m=\u001b[39m readRecoHitsFromRootFiles(path\u001b[39m+\u001b[39;49mrootFileWildcard, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     82\u001b[0m alignmentMatices \u001b[39m=\u001b[39m {}\n\u001b[1;32m     84\u001b[0m \u001b[39m# translate the reco hits to format for module Aligner\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [10], line 37\u001b[0m, in \u001b[0;36mreadRecoHitsFromRootFiles\u001b[0;34m(filename, maxNoOfFiles)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhmmm...\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mids\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39m# make a real 2D array from array[array[ ]]\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m maskedIDs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mstack(ids[mask])\n\u001b[1;32m     39\u001b[0m \u001b[39m# calculate module number from sensor IDs\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# use look up table for that\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m# thank you TheodrosZelleke for this insanely smart idea\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# https://stackoverflow.com/a/14448935\u001b[39;00m\n\u001b[1;32m     43\u001b[0m sectorIDfromLut \u001b[39m=\u001b[39m sectorIDlut[maskedIDs]\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/numpy/core/shape_base.py:426\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    424\u001b[0m shapes \u001b[39m=\u001b[39m {arr\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays}\n\u001b[1;32m    425\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shapes) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 426\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mall input arrays must have the same shape\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    428\u001b[0m result_ndim \u001b[39m=\u001b[39m arrays[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mndim \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    429\u001b[0m axis \u001b[39m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "def readRecoHitsFromRootFiles(filename, maxNoOfFiles=0):\n",
    "\n",
    "    # make empty 3D (n x 4 x 4) result array.\n",
    "    # n tracks, 4 reco hits per track (all others are discarded),\n",
    "    # 4 vales per reco (sector id, x, y, z)\n",
    "    resultTracks = np.empty((0, 4, 4))\n",
    "\n",
    "    runIndex = 0\n",
    "    for arrayDict in uproot.iterate(\n",
    "        filename,\n",
    "        [\n",
    "            \"LMDHitsMerged.fSensorID\",\n",
    "            \"LMDHitsMerged.fX\",\n",
    "            \"LMDHitsMerged.fY\",\n",
    "            \"LMDHitsMerged.fZ\",\n",
    "        ],\n",
    "        library=\"np\",\n",
    "        allow_missing=True,  # some files may be empty, skip those\n",
    "    ):\n",
    "        ids = arrayDict[\"LMDHitsMerged.fSensorID\"]\n",
    "        recoX = arrayDict[\"LMDHitsMerged.fX\"]\n",
    "        recoY = arrayDict[\"LMDHitsMerged.fY\"]\n",
    "        recoZ = arrayDict[\"LMDHitsMerged.fZ\"]\n",
    "        \n",
    "        print(f'len before mask: {len(ids)}')\n",
    "        # print(f'looks like this:\\n{arrayDict}')\n",
    "\n",
    "        # create mask for events that have exactly 4 hits\n",
    "        mask = [event.size > 3 for event in ids]\n",
    "        print(f'len after mask: {len(ids[mask])}')\n",
    "\n",
    "        testarray = ids\n",
    "\n",
    "        print(f'hmmm...\\n{ids}')\n",
    "        print(f'hmmm...\\n{recoX}')\n",
    "        print(f'hmmm...\\n{recoY}')\n",
    "        print(f'hmmm...\\n{recoZ}')\n",
    "\n",
    "        # make a real 2D array from array[array[ ]]\n",
    "        maskedIDs = np.stack(ids[mask])\n",
    "\n",
    "        # calculate module number from sensor IDs\n",
    "        # use look up table for that\n",
    "        # thank you TheodrosZelleke for this insanely smart idea\n",
    "        # https://stackoverflow.com/a/14448935\n",
    "        sectorIDfromLut = sectorIDlut[maskedIDs]\n",
    "\n",
    "        # make arrays of arrays to 2d arrays\n",
    "        xFlat = np.stack(recoX[mask])\n",
    "        yFlat = np.stack(recoY[mask])\n",
    "        zFlat = np.stack(recoZ[mask])\n",
    "\n",
    "        # transpose to assemble and transpose again\n",
    "        theseTracks = np.array([sectorIDfromLut.T, xFlat.T, yFlat.T, zFlat.T]).T\n",
    "\n",
    "        # sort every 4-hit combo by z value. do this for every event.\n",
    "        # this is REQUIRED for the aligner\n",
    "        # I know it looks weird seeing a list comprehension here instead of something\n",
    "        # more NumPythonic, but this seems to be fastest after all\n",
    "        # the numpy version would probably look like this:\n",
    "        # sortedResultArray = theseTracks[:,theseTracks[:,:,3].argsort()]\n",
    "        # or \n",
    "        # sortedResultArray = np.einsum('iijk->ijk', theseTracks[:,theseTracks[:,:,0].argsort()])\n",
    "        # and be 20x slower (and require MUCH more memory)\n",
    "        sortedResultArray = np.array([subarray[subarray[:,3].argsort()] for subarray in theseTracks])\n",
    "\n",
    "        print(f'so this is what i got now:\\n{sortedResultArray}')\n",
    "\n",
    "        # stack this files' content with the others\n",
    "        resultTracks = np.vstack((resultTracks, sortedResultArray))\n",
    "\n",
    "        runIndex += 1\n",
    "        if runIndex == maxNoOfFiles:\n",
    "            break\n",
    "\n",
    "    return resultTracks\n",
    "\n",
    "# path = \"/mnt/himsterData/roklasen/LumiFit/plab_1.50GeV/dpm_elastic_theta_2.7-13.0mrad_recoil_corrected/ip_offset_XYZDXDYDZ_0.0_0.0_0.0_0.0_0.0_0.0/beam_grad_XYDXDY_0.0_0.0_0.0_0.0/geo_misalignmentmisMat-modules/100000/1-100_uncut/no_alignment_correction/\"\n",
    "path = \"/media/CacheDrive2TB/Arbeit/PandaRoot/macro/detectors/lmd/testFullChain/mom-15/\"\n",
    "# path = \"/media/CacheDrive2TB/Arbeit/PandaRoot/macro/detectors/lmd/testFullChain/mom-1_5/\"\n",
    "rootFileWildcard = \"Lumi_recoMerged_*.root:pndsim\"\n",
    "\n",
    "resultArray = readRecoHitsFromRootFiles(path+rootFileWildcard, 1)\n",
    "\n",
    "alignmentMatices = {}\n",
    "\n",
    "# translate the reco hits to format for module Aligner\n",
    "for i in range(10):\n",
    "    # apply mask so only one sector is chosen\n",
    "    # careful, this only checks if the first hit\n",
    "    # is in the correct sector!\n",
    "    sectorMask = resultArray[:, 0, 0] == i\n",
    "\n",
    "    # create new empty array thay has the required structure\n",
    "    sectorTracksXYZ = resultArray[sectorMask][:, :, 1:4]\n",
    "    nTrks = len(sectorTracksXYZ)\n",
    "\n",
    "    # assign recos from input array to new array for this sector\n",
    "    trackVectorForAligner = np.ones((nTrks, 6, 4))\n",
    "    trackVectorForAligner[:, 2:6, :3] = sectorTracksXYZ[:, 0:4]\n",
    "    break\n",
    "\n",
    "    alignmentMatices |= alignSectorICP(trackVectorForAligner, i)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
